"""
–ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ PostgreSQL –∏–∑ Excel –æ—Ç—á–µ—Ç–∞
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ –æ–ø—ã—Ç–Ω—ã–π DBA –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç
"""

import pandas as pd
from pathlib import Path
from datetime import datetime
import argparse
import glob


# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
DEFAULT_EXCEL_FILE = "20 RPS.xlsx"  # –§–∞–π–ª –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é


class PostgresAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ PostgreSQL"""
    
    def __init__(self, excel_file):
        self.excel_file = excel_file
        self.sheets = {}
        self.load_data()
    
    def load_data(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –ª–∏—Å—Ç—ã –∏–∑ Excel —Ñ–∞–π–ª–∞"""
        print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel...")
        xl_file = pd.ExcelFile(self.excel_file)
        
        for sheet_name in xl_file.sheet_names:
            try:
                self.sheets[sheet_name] = pd.read_excel(xl_file, sheet_name=sheet_name)
                print(f"  ‚úì {sheet_name}: {len(self.sheets[sheet_name])} —Å—Ç—Ä–æ–∫")
            except Exception as e:
                print(f"  ‚úó –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {sheet_name}: {e}")
    
    def get_report_period(self):
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–µ—Ä–∏–æ–¥ –æ—Ç—á–µ—Ç–∞"""
        props = self.sheets.get('Properties', pd.DataFrame())
        if props.empty:
            return "–ù–µ —É–∫–∞–∑–∞–Ω", "–ù–µ —É–∫–∞–∑–∞–Ω", 0
        
        start = props['report_start1'].iloc[0] if 'report_start1' in props.columns else "–ù–µ —É–∫–∞–∑–∞–Ω"
        end = props['report_end1'].iloc[0] if 'report_end1' in props.columns else "–ù–µ —É–∫–∞–∑–∞–Ω"
        
        # –í—ã—á–∏—Å–ª—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –º–∏–Ω—É—Ç–∞—Ö
        try:
            duration_sec = props['interval_duration_sec'].iloc[0]
            duration_min = int(duration_sec / 60)
        except:
            duration_min = 0
        
        return start, end, duration_min
    
    def analyze_database_stats(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ë–î"""
        df = self.sheets.get('dbstat', pd.DataFrame())
        if df.empty:
            return []
        
        results = []
        
        for _, row in df.iterrows():
            dbname = row.get('dbname', 'Unknown')
            
            # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            cache_hit_ratio = row.get('blks_hit_pct', 0)
            size = row.get('datsize', 'N/A')
            size_delta = row.get('datsize_delta', 'N/A')
            commits = row.get('xact_commit', 0)
            rollbacks = row.get('xact_rollback', 0)
            deadlocks = row.get('deadlocks', 0)
            temp_files = row.get('temp_files', 0)
            temp_bytes = row.get('temp_bytes', 0)
            
            # –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–±–ª–µ–º
            issues = []
            if cache_hit_ratio < 95:
                issues.append(f"‚ö†Ô∏è –ù–∏–∑–∫–∏–π cache hit ratio: {cache_hit_ratio:.2f}%")
            if deadlocks and deadlocks > 0:
                issues.append(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã deadlocks: {deadlocks}")
            if temp_files and temp_files > 0:
                issues.append(f"‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {temp_files} ({temp_bytes})")
            
            rollback_ratio = (rollbacks / (commits + rollbacks) * 100) if (commits + rollbacks) > 0 else 0
            if rollback_ratio > 5:
                issues.append(f"‚ö†Ô∏è –í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç rollback: {rollback_ratio:.2f}%")
            
            results.append({
                'dbname': dbname,
                'size': size,
                'size_delta': size_delta,
                'cache_hit_ratio': cache_hit_ratio,
                'commits': commits,
                'rollbacks': rollbacks,
                'rollback_ratio': rollback_ratio,
                'deadlocks': deadlocks,
                'temp_files': temp_files,
                'temp_bytes': temp_bytes,
                'issues': issues
            })
        
        return results
    
    def get_query_text(self, query_id):
        """–ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –ø–æ –µ–≥–æ ID"""
        queries_df = self.sheets.get('queries', pd.DataFrame())
        if queries_df.empty:
            return None
        
        query_row = queries_df[queries_df['hexqueryid'] == query_id]
        if not query_row.empty:
            query_texts = query_row['query_texts'].iloc[0]
            if isinstance(query_texts, str) and query_texts:
                # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤
                text = ' '.join(query_texts.split())
                return text
        return None
    
    def analyze_top_queries(self, top_n=10):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–∞–º—ã–µ —Ç—è–∂–µ–ª—ã–µ –∑–∞–ø—Ä–æ—Å—ã"""
        df = self.sheets.get('top_statements', pd.DataFrame())
        if df.empty:
            return []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤
        time_col = 'total_exec_time' if 'total_exec_time' in df.columns else 'total_time'
        mean_col = 'mean_exec_time' if 'mean_exec_time' in df.columns else 'mean_time'
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –æ–±—â–µ–º—É –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        df_sorted = df.sort_values(by=time_col, ascending=False).head(top_n)
        
        results = []
        for _, row in df_sorted.iterrows():
            query_id = row.get('hexqueryid', 'N/A')
            dbname = row.get('dbname', 'N/A')
            username = row.get('username', 'N/A')
            calls = row.get('calls', 0)
            total_time = row.get(time_col, 0)
            mean_time = row.get(mean_col, 0)
            rows = row.get('rows', 0)
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞
            query_text = self.get_query_text(query_id)
            query_preview = query_text[:50] if query_text else 'N/A'
            query_preview_suffix = '...' if query_text and len(query_text) > 50 else ''
            
            # –ê–Ω–∞–ª–∏–∑ I/O
            shared_blks_hit = row.get('shared_blks_hit', 0)
            shared_blks_read = row.get('shared_blks_read', 0)
            temp_blks_written = row.get('temp_blks_written', 0)
            
            # –†–∞—Å—á–µ—Ç cache hit ratio –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            total_blks = shared_blks_hit + shared_blks_read
            query_cache_ratio = (shared_blks_hit / total_blks * 100) if total_blks > 0 else 100
            
            # –ü—Ä–æ–±–ª–µ–º—ã
            issues = []
            if mean_time > 1000:
                issues.append(f"–ú–µ–¥–ª–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {mean_time:.2f} –º—Å")
            if temp_blks_written > 0:
                issues.append(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç temp: {temp_blks_written} –±–ª–æ–∫–æ–≤")
            if query_cache_ratio < 90:
                issues.append(f"–ù–∏–∑–∫–∏–π cache hit: {query_cache_ratio:.1f}%")
            
            results.append({
                'query_id': query_id,
                'query_preview': query_preview,
                'query_preview_suffix': query_preview_suffix,
                'dbname': dbname,
                'username': username,
                'calls': calls,
                'total_time': total_time,
                'mean_time': mean_time,
                'rows': rows,
                'cache_ratio': query_cache_ratio,
                'temp_blks': temp_blks_written,
                'issues': issues
            })
        
        return results
    
    def analyze_top_wal_queries(self, top_n=5):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–æ–ø –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ WAL"""
        df = self.sheets.get('top_statements', pd.DataFrame())
        if df.empty:
            return []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ wal_bytes
        if 'wal_bytes' not in df.columns:
            return []
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—Å—ã —Å WAL –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é
        df_wal = df[df['wal_bytes'].notna() & (df['wal_bytes'] > 0)].copy()
        
        if df_wal.empty:
            return []
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ wal_bytes
        df_sorted = df_wal.sort_values(by='wal_bytes', ascending=False).head(top_n)
        
        results = []
        for _, row in df_sorted.iterrows():
            query_id = row.get('hexqueryid', 'N/A')
            wal_bytes = row.get('wal_bytes', 0)
            wal_bytes_pct = row.get('wal_bytes_pct', 0)
            
            query_text = self.get_query_text(query_id)
            query_preview = query_text[:50] if query_text else 'N/A'
            query_preview_suffix = '...' if query_text and len(query_text) > 50 else ''
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ MB/GB
            wal_mb = wal_bytes / (1024 * 1024)
            wal_gb = wal_mb / 1024 if wal_mb > 1024 else 0
            
            results.append({
                'query_id': query_id,
                'query_preview': query_preview,
                'query_preview_suffix': query_preview_suffix,
                'dbname': row.get('dbname', 'N/A'),
                'calls': row.get('calls', 0),
                'wal_bytes': wal_bytes,
                'wal_mb': round(wal_mb, 2),
                'wal_gb': round(wal_gb, 3) if wal_gb > 0 else 0,
                'wal_pct': round(wal_bytes_pct, 2) if wal_bytes_pct else 0
            })
        
        return results
    
    def analyze_wal_stats(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É WAL"""
        df = self.sheets.get('wal_stats', pd.DataFrame())
        if df.empty:
            return {}
        
        row = df.iloc[0]
        
        wal_records = row.get('wal_records', 0)
        wal_fpi = row.get('wal_fpi', 0)
        wal_bytes = row.get('wal_bytes', 0)
        wal_write_time = row.get('wal_write_time', 0)
        wal_sync_time = row.get('wal_sync_time', 0)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ MB/GB
        wal_mb = wal_bytes / (1024 * 1024) if wal_bytes else 0
        wal_gb = wal_mb / 1024
        
        return {
            'records': wal_records,
            'fpi': wal_fpi,
            'bytes': wal_bytes,
            'size_mb': wal_mb,
            'size_gb': wal_gb,
            'write_time': wal_write_time,
            'sync_time': wal_sync_time
        }
    
    def analyze_tables(self, top_n=10):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–∞–±–ª–∏—Ü"""
        df = self.sheets.get('top_tables', pd.DataFrame())
        if df.empty:
            return []
        
        results = []
        
        for _, row in df.iterrows():
            dbname = row.get('dbname', 'N/A')
            schemaname = row.get('schemaname', 'N/A')
            relname = row.get('relname', 'N/A')
            
            n_live_tup = row.get('n_live_tup', 0)
            n_dead_tup = row.get('n_dead_tup', 0)
            n_mod_since_analyze = row.get('n_mod_since_analyze', 0)
            
            seq_scan = row.get('seq_scan', 0)
            idx_scan = row.get('idx_scan', 0)
            
            relsize = row.get('relsize', 'N/A')
            
            # –ü—Ä–æ–±–ª–µ–º—ã
            issues = []
            
            # Bloat –ø—Ä–æ–±–ª–µ–º–∞
            if n_live_tup > 0:
                dead_ratio = (n_dead_tup / n_live_tup * 100)
                if dead_ratio > 20:
                    issues.append(f"‚ö†Ô∏è –ú–Ω–æ–≥–æ –º–µ—Ä—Ç–≤—ã—Ö —Å—Ç—Ä–æ–∫: {dead_ratio:.1f}% ({n_dead_tup:,})")
            
            # –ü—Ä–æ–±–ª–µ–º–∞ —Å ANALYZE
            if n_live_tup > 0 and n_mod_since_analyze > n_live_tup * 0.2:
                issues.append(f"‚ö†Ô∏è –ù—É–∂–µ–Ω ANALYZE: {n_mod_since_analyze:,} –∏–∑–º–µ–Ω–µ–Ω–∏–π")
            
            # Seq scan –Ω–∞ –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü–∞—Ö
            if seq_scan > 100 and n_live_tup > 10000:
                issues.append(f"‚ö†Ô∏è –ú–Ω–æ–≥–æ seq_scan: {seq_scan} (–≤–æ–∑–º–æ–∂–Ω–æ –Ω—É–∂–µ–Ω –∏–Ω–¥–µ–∫—Å)")
            
            if issues:  # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã
                results.append({
                    'dbname': dbname,
                    'schema': schemaname,
                    'table': relname,
                    'size': relsize,
                    'live_tuples': n_live_tup,
                    'dead_tuples': n_dead_tup,
                    'seq_scan': seq_scan,
                    'idx_scan': idx_scan,
                    'mod_since_analyze': n_mod_since_analyze,
                    'issues': issues
                })
        
        return sorted(results, key=lambda x: len(x['issues']), reverse=True)[:top_n]
    
    def analyze_indexes(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤"""
        df = self.sheets.get('top_indexes', pd.DataFrame())
        if df.empty:
            return []
        
        results = []
        
        for _, row in df.iterrows():
            idx_scan = row.get('idx_scan', 0)
            
            # –ò—â–µ–º –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–Ω–¥–µ–∫—Å—ã
            if idx_scan == 0:
                results.append({
                    'dbname': row.get('dbname', 'N/A'),
                    'schema': row.get('schemaname', 'N/A'),
                    'table': row.get('relname', 'N/A'),
                    'index': row.get('indexrelname', 'N/A'),
                    'size': row.get('indexrelsize', 'N/A'),
                    'scans': idx_scan
                })
        
        return results
    
    def generate_markdown_report(self, output_file):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Markdown –æ—Ç—á–µ—Ç"""
        print(f"\n–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –≤ {output_file}...")
        
        start, end, duration = self.get_report_period()
        db_stats = self.analyze_database_stats()
        top_queries = self.analyze_top_queries(10)
        wal_stats = self.analyze_wal_stats()
        top_wal_queries = self.analyze_top_wal_queries(5)
        problem_tables = self.analyze_tables(10)
        unused_indexes = self.analyze_indexes()
        
        with open(output_file, 'w', encoding='utf-8') as f:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            f.write("# üìä –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ PostgreSQL\n\n")
            f.write(f"**–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # –ü–µ—Ä–∏–æ–¥ –æ—Ç—á–µ—Ç–∞
            f.write("## ‚è±Ô∏è –ü–µ—Ä–∏–æ–¥ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞\n\n")
            f.write(f"- **–ù–∞—á–∞–ª–æ**: `{start}`\n")
            f.write(f"- **–ö–æ–Ω–µ—Ü**: `{end}`\n")
            f.write(f"- **–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å**: {duration} –º–∏–Ω—É—Ç\n\n")
            
            f.write("---\n\n")
            
            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ë–î
            f.write("## üóÑÔ∏è –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö\n\n")
            
            for db in db_stats:
                f.write(f"### –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: `{db['dbname']}`\n\n")
                f.write(f"| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |\n")
                f.write(f"|---------|----------|\n")
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è, –∑–∞–º–µ–Ω—è—è nan –Ω–∞ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
                size_str = '' if pd.isna(db['size']) else str(db['size'])
                size_delta_str = '' if pd.isna(db['size_delta']) else str(db['size_delta'])
                commits_str = f"{int(db['commits']):,}" if pd.notna(db['commits']) else ''
                rollbacks_str = f"{int(db['rollbacks']):,}" if pd.notna(db['rollbacks']) else ''
                rollback_ratio_str = f"({db['rollback_ratio']:.2f}%)" if pd.notna(db['rollback_ratio']) and rollbacks_str else ''
                deadlocks_str = '' if pd.isna(db['deadlocks']) or db['deadlocks'] == 0 else str(int(db['deadlocks']))
                temp_files_str = '' if pd.isna(db['temp_files']) or db['temp_files'] == 0 else str(int(db['temp_files']))
                
                f.write(f"| **–†–∞–∑–º–µ—Ä –ë–î** | {size_str} |\n")
                f.write(f"| **–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞** | {size_delta_str} |\n")
                f.write(f"| **Cache Hit Ratio** | {db['cache_hit_ratio']:.2f}% |\n")
                f.write(f"| **Commits** | {commits_str} |\n")
                f.write(f"| **Rollbacks** | {rollbacks_str} {rollback_ratio_str} |\n")
                f.write(f"| **Deadlocks** | {deadlocks_str} |\n")
                f.write(f"| **–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã** | {temp_files_str} |\n\n")
                
                if db['issues']:
                    f.write("**‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:**\n\n")
                    for issue in db['issues']:
                        f.write(f"- {issue}\n")
                    f.write("\n")
                else:
                    f.write("‚úÖ **–ü—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ**\n\n")
            
            f.write("---\n\n")
            
            # WAL —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            f.write("## üìù –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ Write-Ahead Log (WAL)\n\n")
            
            if wal_stats:
                f.write(f"| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |\n")
                f.write(f"|---------|----------|\n")
                f.write(f"| **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π** | {wal_stats['records']:,} |\n")
                f.write(f"| **Full Page Images** | {wal_stats['fpi']:,} |\n")
                f.write(f"| **–û–±—ä–µ–º WAL** | {wal_stats['size_mb']:.2f} MB ({wal_stats['size_gb']:.3f} GB) |\n")
                f.write(f"| **–í—Ä–µ–º—è –∑–∞–ø–∏—Å–∏** | {wal_stats['write_time']:.2f} –º—Å |\n")
                f.write(f"| **–í—Ä–µ–º—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏** | {wal_stats['sync_time']:.2f} –º—Å |\n\n")
                
                # –ê–Ω–∞–ª–∏–∑
                wal_per_min = wal_stats['size_mb'] / duration if duration > 0 else 0
                f.write(f"**–°–∫–æ—Ä–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ WAL**: {wal_per_min:.2f} MB/–º–∏–Ω\n\n")
                
                if wal_per_min > 100:
                    f.write("‚ö†Ô∏è **–í—ã—Å–æ–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ WAL** - –≤–æ–∑–º–æ–∂–Ω–æ –º–Ω–æ–≥–æ –æ–ø–µ—Ä–∞—Ü–∏–π –∑–∞–ø–∏—Å–∏\n\n")
                elif wal_per_min > 50:
                    f.write("‚ö° **–£–º–µ—Ä–µ–Ω–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∑–∞–ø–∏—Å–∏**\n\n")
                else:
                    f.write("‚úÖ **–ù–æ—Ä–º–∞–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∑–∞–ø–∏—Å–∏**\n\n")
            else:
                f.write("*–î–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã*\n\n")
            
            # –¢–æ–ø –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ WAL
            if top_wal_queries:
                f.write("### üìä –¢–æ–ø-5 –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ WAL\n\n")
                f.write("*–ó–∞–ø—Ä–æ—Å—ã —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –æ–±—ä–µ–º–æ–º Write-Ahead Log*\n\n")
                
                for i, query in enumerate(top_wal_queries, 1):
                    f.write(f"**{i}. Query ID:** `{query['query_id']}`\n\n")
                    f.write(f"- **SQL Preview:** `{query['query_preview']}{query['query_preview_suffix']}`\n")
                    f.write(f"- **–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö:** {query['dbname']}\n")
                    f.write(f"- **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–∑–æ–≤–æ–≤:** {query['calls']:,}\n")
                    f.write(f"- **–û–±—ä–µ–º WAL:** {query['wal_mb']:.2f} MB")
                    
                    if query['wal_pct'] > 0:
                        f.write(f" ‚Äî {query['wal_pct']:.1f}% –æ—Ç –æ–±—â–µ–≥–æ WAL")
                    
                    f.write("\n\n")
                
                f.write("\n")
            
            f.write("---\n\n")
            
            # –¢–æ–ø —Ç—è–∂–µ–ª—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            f.write("## üî• –¢–æ–ø —Å–∞–º—ã—Ö —Ç—è–∂–µ–ª—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤\n\n")
            
            if top_queries:
                f.write(f"*–ê–Ω–∞–ª–∏–∑ {len(top_queries)} –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –≤—Ä–µ–º–µ–Ω–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è*\n\n")
                
                for i, query in enumerate(top_queries, 1):
                    f.write(f"### {i}. Query ID: `{query['query_id']}`\n\n")
                    f.write(f"**SQL Preview:** `{query['query_preview']}{query['query_preview_suffix']}`\n\n")
                    f.write(f"| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ |\n")
                    f.write(f"|----------|----------|\n")
                    f.write(f"| **–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö** | {query['dbname']} |\n")
                    f.write(f"| **–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å** | {query['username']} |\n")
                    f.write(f"| **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–∑–æ–≤–æ–≤** | {query['calls']:,} |\n")
                    f.write(f"| **–û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è** | {query['total_time']*1000:.0f} –º—Å |\n")
                    f.write(f"| **–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è** | {query['mean_time']:.2f} –º—Å |\n")
                    
                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ NaN
                    rows_value = query['rows']
                    rows_str = f"{int(rows_value):,}" if pd.notna(rows_value) and rows_value > 0 else ""
                    f.write(f"| **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫** | {rows_str} |\n")
                    
                    f.write(f"| **Cache Hit Ratio** | {query['cache_ratio']:.1f}% |\n")
                    
                    if query['temp_blks'] > 0:
                        f.write(f"| **–í—Ä–µ–º–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏** | {query['temp_blks']:,} |\n")
                    
                    f.write("\n")
                    
                    if query['issues']:
                        f.write("**‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã:**\n\n")
                        for issue in query['issues']:
                            f.write(f"- {issue}\n")
                        f.write("\n")
                    else:
                        f.write("‚úÖ **–ó–∞–ø—Ä–æ—Å —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ**\n\n")
                    
                    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                    recommendations = []
                    if query['mean_time'] > 1000:
                        recommendations.append("–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –∑–∞–ø—Ä–æ—Å–∞ –∏–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤")
                    if query['temp_blks'] > 0:
                        recommendations.append("–£–≤–µ–ª–∏—á–∏—Ç—å `work_mem` –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
                    if query['cache_ratio'] < 90:
                        recommendations.append("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏–Ω–¥–µ–∫—Å—ã –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–∞–±–ª–∏—Ü")
                    
                    if recommendations:
                        f.write("**üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**\n\n")
                        for rec in recommendations:
                            f.write(f"- {rec}\n")
                        f.write("\n")
                    
                    f.write("---\n\n")
            else:
                f.write("*–î–∞–Ω–Ω—ã–µ –æ –∑–∞–ø—Ä–æ—Å–∞—Ö –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã*\n\n")
            
            # –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã
            if problem_tables:
                f.write("## üóÇÔ∏è –¢–∞–±–ª–∏—Ü—ã —Ç—Ä–µ–±—É—é—â–∏–µ –≤–Ω–∏–º–∞–Ω–∏—è\n\n")
                
                for i, table in enumerate(problem_tables, 1):
                    f.write(f"### {i}. `{table['schema']}.{table['table']}`\n\n")
                    f.write(f"| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ |\n")
                    f.write(f"|----------|----------|\n")
                    f.write(f"| **–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö** | {table['dbname']} |\n")
                    f.write(f"| **–†–∞–∑–º–µ—Ä** | {table['size']} |\n")
                    f.write(f"| **–ñ–∏–≤—ã—Ö —Å—Ç—Ä–æ–∫** | {table['live_tuples']:,} |\n")
                    f.write(f"| **–ú–µ—Ä—Ç–≤—ã—Ö —Å—Ç—Ä–æ–∫** | {table['dead_tuples']:,} |\n")
                    f.write(f"| **Seq Scan** | {table['seq_scan']:,} |\n")
                    f.write(f"| **Index Scan** | {table['idx_scan']:,} |\n")
                    f.write(f"| **–ò–∑–º–µ–Ω–µ–Ω–∏–π —Å ANALYZE** | {table['mod_since_analyze']:,} |\n\n")
                    
                    f.write("**‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã:**\n\n")
                    for issue in table['issues']:
                        f.write(f"- {issue}\n")
                    f.write("\n")
                    
                    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                    f.write("**üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**\n\n")
                    if table['dead_tuples'] > table['live_tuples'] * 0.2:
                        f.write(f"- –í—ã–ø–æ–ª–Ω–∏—Ç—å `VACUUM ANALYZE {table['schema']}.{table['table']};`\n")
                    if table['mod_since_analyze'] > table['live_tuples'] * 0.2:
                        f.write(f"- –í—ã–ø–æ–ª–Ω–∏—Ç—å `ANALYZE {table['schema']}.{table['table']};`\n")
                    if table['seq_scan'] > 100 and table['live_tuples'] > 10000:
                        f.write(f"- –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å —Å–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è —á–∞—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤\n")
                    f.write("\n")
                    
                    f.write("---\n\n")
            
            # –ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–Ω–¥–µ–∫—Å—ã
            if unused_indexes:
                f.write("## üîç –ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–Ω–¥–µ–∫—Å—ã\n\n")
                f.write("*–ò–Ω–¥–µ–∫—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å –∑–∞ –ø–µ—Ä–∏–æ–¥ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞*\n\n")
                
                f.write("| –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö | –°—Ö–µ–º–∞ | –¢–∞–±–ª–∏—Ü–∞ | –ò–Ω–¥–µ–∫—Å | –†–∞–∑–º–µ—Ä |\n")
                f.write("|-------------|-------|---------|--------|--------|\n")
                
                for idx in unused_indexes[:10]:
                    f.write(f"| {idx['dbname']} | {idx['schema']} | {idx['table']} | {idx['index']} | {idx['size']} |\n")
                
                f.write("\n**üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å —É–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞ –∏ —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ INSERT/UPDATE –æ–ø–µ—Ä–∞—Ü–∏–π.\n\n")
                f.write("```sql\n")
                f.write("-- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –ø–µ—Ä–µ–¥ —É–¥–∞–ª–µ–Ω–∏–µ–º:\n")
                for idx in unused_indexes[:3]:
                    f.write(f"DROP INDEX IF EXISTS {idx['schema']}.{idx['index']};\n")
                f.write("```\n\n")
                f.write("---\n\n")
            
            # –û–±—â–∏–µ –≤—ã–≤–æ–¥—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            f.write("## üìã –û–±—â–∏–µ –≤—ã–≤–æ–¥—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n\n")
            
            f.write("### ‚úÖ –ß—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ\n\n")
            
            good_things = []
            for db in db_stats:
                if db['cache_hit_ratio'] >= 95:
                    good_things.append(f"–û—Ç–ª–∏—á–Ω—ã–π cache hit ratio –≤ –ë–î `{db['dbname']}`: {db['cache_hit_ratio']:.2f}%")
                if db['deadlocks'] == 0:
                    good_things.append(f"–ù–µ—Ç deadlocks –≤ –ë–î `{db['dbname']}`")
            
            if not good_things:
                good_things.append("–ë–∞–∑–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ —Ü–µ–ª–æ–º —Å—Ç–∞–±–∏–ª—å–Ω–æ")
            
            for item in good_things:
                f.write(f"- {item}\n")
            
            f.write("\n### ‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã\n\n")
            
            critical = []
            for db in db_stats:
                if db['cache_hit_ratio'] < 90:
                    critical.append(f"**–û—á–µ–Ω—å –Ω–∏–∑–∫–∏–π cache hit ratio** –≤ `{db['dbname']}`: {db['cache_hit_ratio']:.2f}% - –Ω—É–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å `shared_buffers`")
                if db['deadlocks'] and db['deadlocks'] > 0:
                    critical.append(f"**Deadlocks** –≤ `{db['dbname']}`: {db['deadlocks']} - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏–∫—É –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è")
            
            if not critical:
                f.write("- –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ ‚úÖ\n")
            else:
                for item in critical:
                    f.write(f"- {item}\n")
            
            f.write("\n### üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n\n")
            
            recommendations = []
            
            # –ê–Ω–∞–ª–∏–∑ –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            for db in db_stats:
                if db['temp_files'] and db['temp_files'] > 0:
                    recommendations.append("**–£–≤–µ–ª–∏—á–∏—Ç—å work_mem** - –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
                if 90 <= db['cache_hit_ratio'] < 95:
                    recommendations.append(f"**–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å —É–≤–µ–ª–∏—á–µ–Ω–∏–µ shared_buffers** - cache hit ratio {db['cache_hit_ratio']:.2f}% –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å")
            
            if problem_tables:
                recommendations.append("**–ù–∞—Å—Ç—Ä–æ–∏—Ç—å autovacuum** - –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ç–∞–±–ª–∏—Ü—ã —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –º–µ—Ä—Ç–≤—ã—Ö —Å—Ç—Ä–æ–∫")
            
            if unused_indexes:
                recommendations.append(f"**–£–¥–∞–ª–∏—Ç—å {len(unused_indexes)} –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤** - –æ—Å–≤–æ–±–æ–¥–∏—Ç –º–µ—Å—Ç–æ –∏ —É—Å–∫–æ—Ä–∏—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏ –∑–∞–ø–∏—Å–∏")
            
            heavy_queries = [q for q in top_queries if q['mean_time'] > 1000]
            if heavy_queries:
                recommendations.append(f"**–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å {len(heavy_queries)} –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤** - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ EXPLAIN ANALYZE –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            
            if not recommendations:
                recommendations.append("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ —Ö–æ—Ä–æ—à–æ, –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–µ—Ç")
            
            for i, rec in enumerate(recommendations, 1):
                f.write(f"{i}. {rec}\n")
            
            f.write("\n---\n\n")
            
            # –§—É—Ç–µ—Ä
            f.write("## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\n\n")
            f.write("**–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö**: `report--postgres-8360-8361.xlsx`\n\n")
            f.write("**–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∞–Ω–∞–ª–∏–∑–∞**: Python, pandas, openpyxl\n\n")
            f.write("**–ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è**: –ê–Ω–∞–ª–∏–∑ –≤–∫–ª—é—á–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–æ–≤, ")
            f.write("–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ç–∞–±–ª–∏—Ü, WAL –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏ –æ–±—â–µ–≥–æ –∑–¥–æ—Ä–æ–≤—å—è –ë–î.\n\n")
            f.write(f"*–û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n")
        
        print(f"‚úì –û—Ç—á–µ—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_file}")


def process_excel_file(excel_file_path):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω Excel —Ñ–∞–π–ª –∏ —Å–æ–∑–¥–∞–µ—Ç –æ—Ç—á–µ—Ç"""
    excel_file = Path(excel_file_path)
    
    if not excel_file.exists():
        print(f"‚ùå –û—à–∏–±–∫–∞: —Ñ–∞–π–ª {excel_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return False
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ MD —Ñ–∞–π–ª–∞: ReportDB_(–∏–º—è excel).md
    base_name = excel_file.stem  # –ò–º—è –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
    output_file = excel_file.parent / f"ReportDB_{base_name}.md"
    
    print("=" * 70)
    print(f"–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞: {excel_file.name}")
    print("=" * 70)
    print()
    
    try:
        analyzer = PostgresAnalyzer(excel_file)
        analyzer.generate_markdown_report(output_file)
        
        print()
        print("=" * 70)
        print(f"‚úì –§–∞–π–ª {excel_file.name} —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!")
        print(f"  –°–æ–∑–¥–∞–Ω –æ—Ç—á–µ—Ç: {output_file.name}")
        print("=" * 70)
        print()
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ {excel_file.name}: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    parser = argparse.ArgumentParser(
        description='–ê–Ω–∞–ª–∏–∑ PostgreSQL —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑ Excel –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è DBA –æ—Ç—á–µ—Ç–∞',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  %(prog)s                           # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ–∞–π–ª –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
  %(prog)s report.xlsx               # –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–¥–∏–Ω —Ñ–∞–π–ª
  %(prog)s *.xlsx                    # –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ Excel —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ
  %(prog)s "20 RPS.xlsx" "40 RPS.xlsx"  # –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤
  %(prog)s C:/reports/*.xlsx         # –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª—ã –ø–æ –ø—É—Ç–∏ —Å –º–∞—Å–∫–æ–π
        """
    )
    
    parser.add_argument(
        'files',
        nargs='*',
        help=f'–ü—É—Ç—å –∫ Excel —Ñ–∞–π–ª—É(–∞–º) –∏–ª–∏ –º–∞—Å–∫–∞ (*.xlsx). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: {DEFAULT_EXCEL_FILE}'
    )
    
    args = parser.parse_args()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    files_to_process = []
    
    if args.files:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç
        for file_pattern in args.files:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω wildcards
            if '*' in file_pattern or '?' in file_pattern:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º glob –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤
                matched_files = glob.glob(file_pattern)
                if matched_files:
                    files_to_process.extend(matched_files)
                else:
                    print(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ø–∞—Ç—Ç–µ—Ä–Ω '{file_pattern}' –Ω–µ —Å–æ–≤–ø–∞–ª –Ω–∏ —Å –æ–¥–Ω–∏–º —Ñ–∞–π–ª–æ–º")
            else:
                # –û–±—ã—á–Ω—ã–π —Ñ–∞–π–ª
                files_to_process.append(file_pattern)
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–π–ª –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        default_path = Path(__file__).parent / DEFAULT_EXCEL_FILE
        files_to_process.append(str(default_path))
    
    if not files_to_process:
        print("‚ùå –û—à–∏–±–∫–∞: –Ω–µ —É–∫–∞–∑–∞–Ω—ã —Ñ–∞–π–ª—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏!")
        parser.print_help()
        return
    
    print()
    print("=" * 70)
    print("–ê–Ω–∞–ª–∏–∑ PostgreSQL —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑ Excel")
    print("=" * 70)
    print(f"\n–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(files_to_process)}\n")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
    success_count = 0
    failed_count = 0
    
    for excel_file in files_to_process:
        if process_excel_file(excel_file):
            success_count += 1
        else:
            failed_count += 1
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print()
    print("=" * 70)
    print("–ò—Ç–æ–≥–∏ –∞–Ω–∞–ª–∏–∑–∞:")
    print("=" * 70)
    print(f"‚úì –£—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {success_count}")
    if failed_count > 0:
        print(f"‚úó –û—à–∏–±–æ–∫: {failed_count}")
    print("=" * 70)


if __name__ == "__main__":
    main()
